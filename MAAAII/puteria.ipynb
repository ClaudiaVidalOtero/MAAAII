{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Práctica de Aprendizaje Semi-Supervisado con CIFAR-100\n",
    "\n",
    "En esta práctica se desarrollan distintos enfoques para el aprendizaje semi-supervisado sobre el conjunto de datos CIFAR-100. Se parte de un conjunto de 50.000 instancias de entrenamiento y 10.000 instancias de prueba (etiquetadas en 100 clases). Se procede a eliminar el 80% de las etiquetas en el conjunto de entrenamiento, obteniéndose:\n",
    "- 10.000 instancias etiquetadas\n",
    "- 40.000 instancias sin etiquetar\n",
    "\n",
    "A continuación se detallan los ejercicios a desarrollar:\n",
    "1. Entrenar un modelo (con al menos 4 capas densas y/o convolucionales) utilizando únicamente los datos etiquetados.\n",
    "2. Entrenar el mismo modelo usando auto-aprendizaje (self-training) para incorporar los datos sin etiquetar.\n",
    "3. Entrenar un modelo semi-supervisado tipo autoencoder en dos pasos: primero entrenar el autoencoder (utilizando la misma arquitectura encoder que en 1 y 2, salvo el último bloque) y luego entrenar el clasificador.\n",
    "4. Entrenar un modelo semi-supervisado de tipo autoencoder en un único paso (reconstrucción y clasificación simultánea).\n",
    "5. Repetir los entrenamientos anteriores eliminando aquellas instancias no etiquetadas atípicas (según la técnica explicada en el Notebook 5, usando un valor de 𝑣 = 0.9).\n",
    "6. Repetir los Ejercicios 3–5 usando la técnica del apartado “Hay vida más allá del autoencoder” (manteniendo la misma arquitectura encoder).\n",
    "\n",
    "## Preparación: Carga y separación de datos\n",
    "\n",
    "Utilizaremos la utilidad de Keras para cargar el conjunto de datos CIFAR-100. Posteriormente se separará el conjunto de entrenamiento en:\n",
    "- 10.000 instancias etiquetadas.\n",
    "- 40.000 instancias sin etiqueta (se ignoran las etiquetas originales para el entrenamiento semi-supervisado).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos etiquetados: (10000, 32, 32, 3) (10000, 100)\n",
      "Datos sin etiquetar: (40000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cargar CIFAR-100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "# Normalización de imágenes\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convertir etiquetas a one-hot para la clasificación\n",
    "y_train_cat = to_categorical(y_train, 100)\n",
    "y_test_cat  = to_categorical(y_test, 100)\n",
    "\n",
    "# Definir número de datos etiquetados (10k) y sin etiquetar (40k)\n",
    "n_labeled = 10000\n",
    "n_total = x_train.shape[0]\n",
    "\n",
    "# Mezclar aleatoriamente el conjunto de entrenamiento\n",
    "indices = np.arange(n_total)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Seleccionar índices para etiquetado y sin etiquetar\n",
    "labeled_indices = indices[:n_labeled]\n",
    "unlabeled_indices = indices[n_labeled:]\n",
    "\n",
    "x_train_labeled = x_train[labeled_indices]\n",
    "y_train_labeled = y_train_cat[labeled_indices]\n",
    "\n",
    "x_train_unlabeled = x_train[unlabeled_indices]\n",
    "# Nota: Las etiquetas originales de x_train_unlabeled se ignoran para el auto-aprendizaje\n",
    "\n",
    "print(\"Datos etiquetados:\", x_train_labeled.shape, y_train_labeled.shape)\n",
    "print(\"Datos sin etiquetar:\", x_train_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 1: Modelo supervisado utilizando únicamente los datos etiquetados\n",
    "\n",
    "En este ejercicio se define y entrena un modelo de TensorFlow basado en una arquitectura que combina capas convolucionales y densas (al menos 4 bloques) utilizando solo los 10.000 ejemplos etiquetados.\n",
    "\n",
    "### Preguntas a responder:\n",
    "a. **¿Qué red has escogido? ¿Por qué? ¿Cómo la has entrenado?**  \n",
    "   Se ha optado por una red CNN simple que consta de dos bloques convolucionales seguidos de capas densas. Se eligió esta arquitectura por su eficacia en tareas de clasificación de imágenes y su relativa simplicidad.\n",
    "\n",
    "b. **¿Cuál es el rendimiento del modelo en entrenamiento? ¿Y en prueba?**  \n",
    "   Se reportarán las métricas de pérdida y precisión tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "c. **Conclusiones**  \n",
    "   Se analizarán las limitaciones al usar pocos datos etiquetados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\108057\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      3\u001b[0m         layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      4\u001b[0m         layers\u001b[38;5;241m.\u001b[39mMaxPooling2D((\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     ])\n\u001b[0;32m     18\u001b[0m model_sup \u001b[38;5;241m=\u001b[39m build_model()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmodel_sup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[0;32m     20\u001b[0m                   loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m                   metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Entrenamiento con solo datos etiquetados\u001b[39;00m\n\u001b[0;32m     24\u001b[0m history_sup \u001b[38;5;241m=\u001b[39m model_sup\u001b[38;5;241m.\u001b[39mfit(x_train_labeled, y_train_labeled,\n\u001b[0;32m     25\u001b[0m                             epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     26\u001b[0m                             validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test_cat),\n\u001b[0;32m     27\u001b[0m                             verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(100, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model_sup = build_model()\n",
    "\n",
    "\n",
    "# Entrenamiento con solo datos etiquetados\n",
    "history_sup = model_sup.fit(x_train_labeled, y_train_labeled,\n",
    "                            epochs=20, batch_size=64,\n",
    "                            validation_data=(x_test, y_test_cat),\n",
    "                            verbose=2)\n",
    "\n",
    "# Evaluación\n",
    "train_loss, train_acc = model_sup.evaluate(x_train_labeled, y_train_labeled, verbose=0)\n",
    "test_loss, test_acc   = model_sup.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(\"Supervisado: Train Accuracy: {:.4f} - Test Accuracy: {:.4f}\".format(train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios del Ejercicio 1\n",
    "\n",
    "- **Arquitectura:** Se utilizó una red CNN con dos bloques convolucionales y una capa densa final para clasificación.\n",
    "- **Entrenamiento:** Se entrenó con 20 épocas usando Adam y una función de pérdida de entropía cruzada.\n",
    "- **Resultados:** Se muestran las métricas en entrenamiento y prueba. Probablemente se observe un rendimiento moderado debido a la cantidad reducida de datos etiquetados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 2: Auto-aprendizaje (Self-Training)\n",
    "\n",
    "En este ejercicio se reutiliza el mismo modelo definido en el Ejercicio 1, pero se incorporan las instancias sin etiquetar mediante la técnica de auto-aprendizaje. La idea es:\n",
    "1. Entrenar el modelo inicialmente con los datos etiquetados.\n",
    "2. Utilizar el modelo para predecir etiquetas en los datos sin etiquetar.\n",
    "3. Seleccionar aquellas predicciones con alta certeza (por ejemplo, una probabilidad mayor a un umbral definido) y agregarlas al conjunto de entrenamiento, ponderando (opcionalmente) su contribución según la confianza.\n",
    "\n",
    "### Preguntas a responder:\n",
    "a. **¿Qué parámetros has definido para el entrenamiento?**  \n",
    "   Se define un umbral de confianza (por ejemplo, 0.9) para aceptar pseudo-etiquetas.\n",
    "\n",
    "b. **Rendimiento en entrenamiento y prueba.**\n",
    "\n",
    "c. **¿Se mejoran los resultados respecto al Ejercicio 1?**\n",
    "\n",
    "d. **Conclusiones sobre los resultados.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral para la certeza de las pseudo-etiquetas\n",
    "confidence_threshold = 0.9\n",
    "\n",
    "# Realizar predicciones en los datos sin etiquetar\n",
    "pseudo_labels_prob = model_sup.predict(x_train_unlabeled)\n",
    "pseudo_labels = np.argmax(pseudo_labels_prob, axis=1)\n",
    "pseudo_labels_cat = to_categorical(pseudo_labels, 100)\n",
    "\n",
    "# Seleccionar aquellos ejemplos con alta confianza\n",
    "max_probs = np.max(pseudo_labels_prob, axis=1)\n",
    "selected = max_probs >= confidence_threshold\n",
    "\n",
    "print(\"Número de pseudo-etiquetas seleccionadas:\", np.sum(selected))\n",
    "\n",
    "# Combinar datos etiquetados con pseudo-etiquetados de alta confianza\n",
    "x_combined = np.concatenate([x_train_labeled, x_train_unlabeled[selected]], axis=0)\n",
    "y_combined = np.concatenate([y_train_labeled, pseudo_labels_cat[selected]], axis=0)\n",
    "\n",
    "# Reiniciar el modelo (o seguir afinando)\n",
    "model_self = build_supervised_model()\n",
    "model_self.compile(optimizer=optimizers.Adam(),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "history_self = model_self.fit(x_combined, y_combined,\n",
    "                              epochs=20, batch_size=64,\n",
    "                              validation_data=(x_test, y_test_cat),\n",
    "                              verbose=2)\n",
    "\n",
    "train_loss_self, train_acc_self = model_self.evaluate(x_combined, y_combined, verbose=0)\n",
    "test_loss_self, test_acc_self   = model_self.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(\"Self-training: Train Accuracy: {:.4f} - Test Accuracy: {:.4f}\".format(train_acc_self, test_acc_self))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios del Ejercicio 2\n",
    "\n",
    "- **Parámetros:** Se ha definido un umbral de confianza de 0.9 para la selección de pseudo-etiquetas.\n",
    "- **Resultados:** Se evalúa el rendimiento en entrenamiento y prueba del modelo entrenado con datos combinados.  \n",
    "- **Comparación:** Se discute si el auto-aprendizaje mejora o no los resultados obtenidos en el Ejercicio 1, teniendo en cuenta que se incorpora información extra con cierto nivel de incertidumbre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Ejercicio 3: Autoencoder en dos pasos\n",
    "\n",
    "Este ejercicio se realiza en dos etapas:\n",
    "1. **Entrenamiento del autoencoder:** Se entrena un autoencoder que utiliza como encoder la parte convolucional (igual que la definida en los ejercicios anteriores, salvo el último bloque) para aprender una representación compacta de las imágenes.\n",
    "2. **Entrenamiento del clasificador:** Se utiliza el encoder preentrenado, se congela y se añade una cabeza de clasificación (capas densas) que se entrena con los datos etiquetados.\n",
    "\n",
    "### Preguntas a responder:\n",
    "a. **Arquitectura y hiperparámetros.**\n",
    "\n",
    "b. **Rendimiento en entrenamiento y prueba.**\n",
    "\n",
    "c. **Comparación con los Ejercicios 1 y 2.**\n",
    "\n",
    "d. **Conclusiones.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el autoencoder\n",
    "def build_autoencoder():\n",
    "    input_img = layers.Input(shape=x_train.shape[1:])\n",
    "    # Encoder: se reutiliza parte de la arquitectura de Ej.1\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    \n",
    "    # Decoder: arquitectura simétrica\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    decoded = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    autoencoder = models.Model(input_img, decoded)\n",
    "    encoder = models.Model(input_img, encoded)\n",
    "    return autoencoder, encoder\n",
    "\n",
    "autoencoder, encoder = build_autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Entrenar el autoencoder con todas las imágenes de entrenamiento (se puede usar tanto etiquetadas como sin etiquetar)\n",
    "x_autoencoder = x_train  # Uso completo del entrenamiento sin distinguir etiqueta\n",
    "autoencoder.fit(x_autoencoder, x_autoencoder,\n",
    "                epochs=20, batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                verbose=2)\n",
    "\n",
    "# %% \n",
    "# Ahora, se congela el encoder y se añade una cabeza de clasificación\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construir el clasificador utilizando el encoder\n",
    "encoded_input = layers.Input(shape=encoder.output_shape[1:])\n",
    "x = layers.Flatten()(encoded_input)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "output = layers.Dense(100, activation='softmax')(x)\n",
    "classifier_head = models.Model(encoded_input, output)\n",
    "\n",
    "# Conectar el encoder y la cabeza de clasificación\n",
    "input_img = layers.Input(shape=x_train.shape[1:])\n",
    "features = encoder(input_img)\n",
    "classifier_output = classifier_head(features)\n",
    "model_autoencoder_classifier = models.Model(input_img, classifier_output)\n",
    "\n",
    "model_autoencoder_classifier.compile(optimizer=optimizers.Adam(),\n",
    "                                     loss='categorical_crossentropy',\n",
    "                                     metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el clasificador con los datos etiquetados\n",
    "history_ae = model_autoencoder_classifier.fit(x_train_labeled, y_train_labeled,\n",
    "                                              epochs=20, batch_size=64,\n",
    "                                              validation_data=(x_test, y_test_cat),\n",
    "                                              verbose=2)\n",
    "\n",
    "train_loss_ae, train_acc_ae = model_autoencoder_classifier.evaluate(x_train_labeled, y_train_labeled, verbose=0)\n",
    "test_loss_ae, test_acc_ae   = model_autoencoder_classifier.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(\"Autoencoder (2 pasos): Train Accuracy: {:.4f} - Test Accuracy: {:.4f}\".format(train_acc_ae, test_acc_ae))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Comentarios del Ejercicio 3\n",
    "\n",
    "- **Arquitectura:**  \n",
    "  - *Autoencoder:* Se entrena un modelo que aprende a reconstruir las imágenes.  \n",
    "  - *Encoder:* Es la parte convolucional preentrenada.  \n",
    "  - *Clasificador:* Se añade una cabeza densa para la clasificación.\n",
    "- **Hiperparámetros:** Se empleó MSE para la reconstrucción y entropía cruzada para la clasificación, con 20 épocas en cada fase.\n",
    "- **Resultados:** Se evalúa el rendimiento en entrenamiento y prueba, y se compara con los enfoques anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 4: Autoencoder con clasificación simultánea (una etapa)\n",
    "\n",
    "En este ejercicio se entrena un modelo que combina la reconstrucción del autoencoder y la clasificación en un único entrenamiento. La arquitectura del encoder es la misma que en el Ejercicio 3 y la combinación encoder+clasificador es similar al del Ejercicio 1.\n",
    "\n",
    "### Preguntas a responder:\n",
    "a. **Arquitectura y hiperparámetros.**\n",
    "\n",
    "b. **Rendimiento en entrenamiento y prueba.**\n",
    "\n",
    "c. **¿Se mejoran los resultados?**\n",
    "\n",
    "d. **Conclusiones.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir un modelo multitarea: reconstrucción y clasificación\n",
    "input_img = layers.Input(shape=x_train.shape[1:])\n",
    "\n",
    "# Encoder (mismo que antes)\n",
    "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "encoded = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "# Rama de reconstrucción (decoder)\n",
    "x_rec = layers.Conv2D(64, (3,3), activation='relu', padding='same')(encoded)\n",
    "x_rec = layers.UpSampling2D((2,2))(x_rec)\n",
    "x_rec = layers.Conv2D(32, (3,3), activation='relu', padding='same')(x_rec)\n",
    "x_rec = layers.UpSampling2D((2,2))(x_rec)\n",
    "decoded = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same', name='decoded')(x_rec)\n",
    "\n",
    "# Rama de clasificación (cabeza)\n",
    "x_cls = layers.Flatten()(encoded)\n",
    "x_cls = layers.Dense(512, activation='relu')(x_cls)\n",
    "classification = layers.Dense(100, activation='softmax', name='classification')(x_cls)\n",
    "\n",
    "model_multi = models.Model(input_img, [decoded, classification])\n",
    "\n",
    "# Compilación con dos pérdidas: reconstrucción (MSE) y clasificación (entropía cruzada).\n",
    "model_multi.compile(optimizer='adam',\n",
    "                    loss={'decoded': 'mse', 'classification': 'categorical_crossentropy'},\n",
    "                    loss_weights={'decoded': 0.5, 'classification': 1.0},\n",
    "                    metrics={'classification': 'accuracy'})\n",
    "\n",
    "# Entrenar el modelo multitarea: para la rama de reconstrucción se usan las imágenes de entrada\n",
    "history_multi = model_multi.fit(x_train_labeled, {'decoded': x_train_labeled, 'classification': y_train_labeled},\n",
    "                                epochs=20, batch_size=64,\n",
    "                                validation_data=(x_test, {'decoded': x_test, 'classification': y_test_cat}),\n",
    "                                verbose=2)\n",
    "\n",
    "# Evaluar solo la parte clasificadora\n",
    "results = model_multi.evaluate(x_test, {'decoded': x_test, 'classification': y_test_cat}, verbose=0)\n",
    "print(\"Multi-tarea: Test Accuracy (clasificación): {:.4f}\".format(results[3]))  # results[3] corresponde a la métrica de 'classification'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Comentarios del Ejercicio 4\n",
    "\n",
    "- **Arquitectura:** Se utiliza un modelo con dos salidas, una para la reconstrucción de la imagen y otra para la clasificación.\n",
    "- **Hiperparámetros:** Se emplean dos pérdidas (ponderadas) y se entrena en 20 épocas.\n",
    "- **Resultados:** Se analizan las métricas de clasificación y se comparan con los ejercicios anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Ejercicio 5: Eliminación de instancias no etiquetadas atípicas\n",
    "\n",
    "En este ejercicio se repiten los entrenamientos de los Ejercicios 1–4 pero se eliminan las instancias sin etiquetar consideradas atípicas en relación con los datos etiquetados. Se utiliza la técnica explicada (por ejemplo, seleccionando solo aquellas pseudo-etiquetas cuya confianza sea superior a 𝑣 = 0.9) y se utiliza la misma arquitectura de clasificación que en el Ejercicio 1, salvo la capa de salida.\n",
    "\n",
    "### Pregunta a responder:\n",
    "a. ¿Se mejoran los resultados con respecto a los ejercicios anteriores? ¿Qué conclusiones se sacan?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ejemplo: Reaplicar el auto-aprendizaje del Ejercicio 2 con selección basada en v=0.9\n",
    "v = 0.9  # umbral definido\n",
    "max_probs = np.max(pseudo_labels_prob, axis=1)\n",
    "selected_v = max_probs >= v\n",
    "print(\"Instancias sin etiqueta seleccionadas (v=0.9):\", np.sum(selected_v))\n",
    "\n",
    "# Se combinan los datos etiquetados con los pseudo-etiquetados filtrados\n",
    "x_combined_v = np.concatenate([x_train_labeled, x_train_unlabeled[selected_v]], axis=0)\n",
    "y_combined_v = np.concatenate([y_train_labeled, pseudo_labels_cat[selected_v]], axis=0)\n",
    "\n",
    "# Reiniciar y entrenar el modelo supervisado (con arquitectura similar a Ej.1)\n",
    "model_filtered = build_supervised_model()\n",
    "model_filtered.compile(optimizer=optimizers.Adam(),\n",
    "                         loss='categorical_crossentropy',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "history_filtered = model_filtered.fit(x_combined_v, y_combined_v,\n",
    "                                      epochs=20, batch_size=64,\n",
    "                                      validation_data=(x_test, y_test_cat),\n",
    "                                      verbose=2)\n",
    "\n",
    "train_loss_f, train_acc_f = model_filtered.evaluate(x_combined_v, y_combined_v, verbose=0)\n",
    "test_loss_f, test_acc_f   = model_filtered.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(\"Filtered Self-training: Train Accuracy: {:.4f} - Test Accuracy: {:.4f}\".format(train_acc_f, test_acc_f))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "### Comentarios del Ejercicio 5\n",
    "\n",
    "- Se ha aplicado la técnica de filtrado utilizando un umbral 𝑣 = 0.9 para eliminar los ejemplos sin etiqueta menos confiables.\n",
    "- Se compara el rendimiento del modelo con el obtenido en ejercicios anteriores.\n",
    "- Se discuten las mejoras y las limitaciones encontradas tras eliminar los datos atípicos.\n",
    "\"\"\"\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "## Ejercicio 6: Uso de la técnica \"Hay vida más allá del autoencoder\"\n",
    "\n",
    "En este ejercicio se repiten los entrenamientos de los Ejercicios 3–5 cambiando el autoencoder por la técnica definida en el apartado “Hay vida más allá del autoencoder”. La arquitectura de la red se mantiene igual que la parte encoder del autoencoder definido anteriormente, y se asegura que el modelo entrene correctamente.\n",
    "\n",
    "### Preguntas a responder:\n",
    "a. Arquitectura y hiperparámetros.\n",
    "b. Rendimiento en entrenamiento y prueba.\n",
    "c. Comparación con los ejercicios anteriores.\n",
    "d. Conclusiones.\n",
    " \n",
    "**Nota:** La implementación de esta técnica puede variar; a continuación se muestra una posible aproximación en la que se modifica el esquema de entrenamiento para obtener representaciones útiles para la clasificación sin reconstruir la imagen completa.\n",
    "\"\"\"\n",
    "\n",
    "# %% \n",
    "# Ejemplo: Construcción de un modelo basado en la técnica alternativa\n",
    "def build_alternative_model():\n",
    "    input_img = layers.Input(shape=x_train.shape[1:])\n",
    "    # Encoder idéntico al anterior\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    encoded = layers.MaxPooling2D((2,2), padding='same')(x)\n",
    "    # Se entrena directamente para clasificación\n",
    "    x_cls = layers.Flatten()(encoded)\n",
    "    x_cls = layers.Dense(512, activation='relu')(x_cls)\n",
    "    classification = layers.Dense(100, activation='softmax')(x_cls)\n",
    "    model_alt = models.Model(input_img, classification)\n",
    "    return model_alt\n",
    "\n",
    "# Entrenar el modelo alternativo utilizando la técnica de filtrado (como en el Ej.5)\n",
    "model_alt = build_alternative_model()\n",
    "model_alt.compile(optimizer=optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Se puede entrenar primero con los datos etiquetados y posteriormente incorporar los pseudo-datos filtrados\n",
    "history_alt_1 = model_alt.fit(x_train_labeled, y_train_labeled,\n",
    "                              epochs=20, batch_size=64,\n",
    "                              validation_data=(x_test, y_test_cat),\n",
    "                              verbose=2)\n",
    "\n",
    "# Incorporar datos pseudo-etiquetados (filtrados con el umbral v=0.9)\n",
    "history_alt_2 = model_alt.fit(x_train_unlabeled[selected_v], pseudo_labels_cat[selected_v],\n",
    "                              epochs=10, batch_size=64,\n",
    "                              validation_data=(x_test, y_test_cat),\n",
    "                              verbose=2)\n",
    "\n",
    "train_loss_alt, train_acc_alt = model_alt.evaluate(x_train_labeled, y_train_labeled, verbose=0)\n",
    "test_loss_alt, test_acc_alt   = model_alt.evaluate(x_test, y_test_cat, verbose=0)\n",
    "print(\"Alternative Model: Train Accuracy: {:.4f} - Test Accuracy: {:.4f}\".format(train_acc_alt, test_acc_alt))\n",
    "\n",
    "# %% [markdown]\n",
    "\"\"\"\n",
    "### Comentarios del Ejercicio 6\n",
    "\n",
    "- **Arquitectura:** Se utiliza la parte encoder del autoencoder para extraer características, a las que se añade una cabeza de clasificación.\n",
    "- **Hiperparámetros:** Se emplean las mismas configuraciones de optimización y pérdida que en los ejercicios anteriores.\n",
    "- **Resultados y comparación:** Se evalúa el rendimiento y se compara con el resto de métodos implementados.\n",
    "- **Conclusiones:** Se discuten las ventajas y desventajas de la técnica alternativa respecto al uso del autoencoder tradicional.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión General\n",
    "\n",
    "En este Notebook se ha demostrado cómo:\n",
    "- El entrenamiento supervisado con pocos datos puede ser limitado.\n",
    "- El auto-aprendizaje permite incorporar datos sin etiquetar y mejorar potencialmente el rendimiento.\n",
    "- Los modelos basados en autoencoder (tanto en dos pasos como en un paso) y técnicas alternativas pueden extraer representaciones robustas para mejorar la clasificación.\n",
    "- El filtrado de ejemplos atípicos (según un umbral de confianza) puede ayudar a evitar el “ruido” de pseudo-etiquetas poco confiables.\n",
    "\n",
    "Cada uno de estos enfoques debe evaluarse en función de las necesidades y limitaciones del problema concreto.\n",
    "\n",
    "> Nota: Los hiperparámetros, número de épocas y umbrales utilizados son ejemplos. En un entorno real, se recomienda realizar un tuning exhaustivo.\n",
    "\n",
    "Este Notebook ofrece un esqueleto que puede adaptarse y ampliarse según las necesidades de la práctica.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
